{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktische Übung 5: Ensemble Learning - Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden wir verschiedene Formen des \"Ensemble Learning\" einsetzen und einen einfachen Bagging-Algorithmus selbst implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorab initialisieren wir die Zufallsgeneratoren um vergleichbare Ergebnisse zu erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.19.1\n",
      "Sklearn version: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Sklearn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für diese Übung verwenden wir den [Wein-Datensatz](https://archive.ics.uci.edu/ml/datasets/wine), welcher ebenfalls ein bekannter Datensatz in der ML-Welt ist.\n",
    "Die offizielle Beschreibung lautet:\n",
    "```\n",
    "These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "```\n",
    "Anhand dieser Merkmale soll die Qualität (Spalte `quality`) des Weins vorhergesagt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/wine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir loslegen, schauen wir uns die Verteilung des Labels an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['quality'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Decision Tree, Random Forest, GBT\n",
    "Trainieren Sie die folgenden Modelle und ermitteln Sie die Accuarcy auf den Testdaten. Geben Sie dabei jeweils den Parameter `random_state=0` bei der Erstellung des Modells and und beschränken Sie die maximale Baumtiefe auf `max_depth=3`.\n",
    "- Einfacher Entscheidungsbaum (`DecisionTreeClassifier`)\n",
    "- Random Forest (`RandomForestClassifier`)\n",
    "- GBT (`GradientBoostingClassifier`)\n",
    "\n",
    "Hinweis: Für diese Modelle müssen wir die Daten nicht skalieren und kein One-hot-encoding durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clfTre = DecisionTreeClassifier(criterion=\"entropy\", random_state=0, max_depth=3)\n",
    "clfTre.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = clfTre.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0, max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=0, max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: GBT Tuning\n",
    "Der `GradientBoostingClassifier` und der `RandomForest` haben als Hyperparameter u.a. die Anzahl der Bäume die trainiert werden (`n_estimators`) und die maximale Baumtiefe (`max_depth`), siehe [hier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).\n",
    "\n",
    "- Führen Sie für beide Modelle ein Cross-Validierung über diese Hyperparameter durch, betrachten Sie dabei folgende Werte:  $n\\_estimators \\in [60, 80, 100, 120, 140]$ und $max\\_depth \\in [2, 3, 4, 5]$. Nehmen Sie das Notebook `6_TreeEnsembles` auf unserem GitHub als Vorlage. Hinweis: Sie können alle Hyperparameter auf einmal übergeben. Mehr Details finden Sie wenn Sie [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) bis nach unten zum Code-Beispiel scrollen.\n",
    "- Welches sind die besten Parameter für `max_depth` und `n_estimators` und welches ist das bessere Modell?\n",
    "- Trainieren Sie das bessere Modelle mit den besten Parametern und machen Sie eine Vorhersage auf den Testdaten. Vergleichen Sie die Ergebnisse mit Aufgabe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = [{'max_depth': [2, 3, 4, 5], 'n_estimators': [60,80,100,120,140]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [2, 3, 4, 5],\n",
       "                          'n_estimators': [60, 80, 100, 120, 140]}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbt = GradientBoostingClassifier(random_state=0)\n",
    "grid_clf = GridSearchCV(estimator=gbt, param_grid=parameter_candidates, n_jobs=-1)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 100\n",
      "Best max_depth: 5\n",
      "Best score: 0.6512837009803921\n"
     ]
    }
   ],
   "source": [
    "print('Best n_estimators:', grid_clf.best_estimator_.n_estimators) \n",
    "print('Best max_depth:', grid_clf.best_estimator_.max_depth)\n",
    "print('Best score:', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [2, 3, 4, 5],\n",
       "                          'n_estimators': [60, 80, 100, 120, 140]}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "grid_clf = GridSearchCV(estimator=rf, param_grid=parameter_candidates, n_jobs=-1)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 60\n",
      "Best max_depth: 5\n",
      "Best score: 0.6114246323529412\n"
     ]
    }
   ],
   "source": [
    "print('Best n_estimators:', grid_clf.best_estimator_.n_estimators) \n",
    "print('Best max_depth:', grid_clf.best_estimator_.max_depth)\n",
    "print('Best score:', grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(random_state=0, max_depth=5, n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinweis: Es hat sich gezeigt, dass mit unterschiedlichen Library-Versionen auch unterschiedliche Ergebnisse für `n_estimators` und `max_depth` gefunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Bagging-Modell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie ein Bagging-Modell von Hand (d.h. nicht die Sklearn-Library verwenden) und testen Sie es auf den Testdaten. Das Bagging-Modell soll folgende Eigenschaften haben:\n",
    "- Das Modell soll 10 Basismodelle haben, welche einfache `DecisionTreeClassifier` sind.\n",
    "- Jeder dieser DecisionTrees soll auf 70% der Trainingsdaten trainiert werden (Sampling mit Zurücklegen). Tipp: Nutzen Sie `X_train.sample(...)`.\n",
    "- Bei der Vorhersage soll die am häufigsten vorhergesagte Klasse als Gesamtvorhersage dienen.\n",
    "- Testen Sie das Modell auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trees = 10\n",
    "subsample_size = 0.7\n",
    "trees = []\n",
    "for i in range(0, no_trees):\n",
    "    X_bootstrap = X_train.sample(frac=subsample_size, replace=True, random_state=i)\n",
    "    y_bootstrap = y_train[X_bootstrap.index]\n",
    "    clfTre = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "    clfTre.fit(X_bootstrap, y_bootstrap)\n",
    "    trees.append(clfTre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Ergebnisse reproduzierbar zu machen, wird bei der `sample`-Methode ein `random_state` übergeben. Dieser `random_state` wird in jedem Schleifendurchlauf auf andere Zahl gesetzt, weil ansonsten immer die gleichen Daten gesampelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "test_predictions = []\n",
    "for data_point in X_test.values:\n",
    "    predictions = [tree.predict([data_point])[0] for tree in trees]\n",
    "    predicted_class = mode(predictions)\n",
    "    test_predictions.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
